<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EIT NLP - Home</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="header-content">
            <nav>
                <ul>
                    <li><h1>EIT NLP</h1></li>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="research.html">Publications</a></li>
                    <li><a href="team.html">Team</a></li>
                    <li><a href="recruitment.html">Join us</a></li>
                </ul>
            </nav>
            <div class="language-switch">
                <a href="index-zh.html">中文</a>
            </div>
        </div>
    </header>

    <main>
        <div class="hero-image">
            <div class="hero-text">
                <h2>Welcome to the Natural Language Processing Group at Eastern Institute of Technology, Ningbo!</h2>
            </div>
            <a href="https://www.eitech.edu.cn/" target="_blank">learn more</a>
        </div>

        <section>
            <h2>About us</h2>
            <p class="about-us-text">Our research explores exciting areas like information retrieval, multi-modal learning, and chain-of-thought reasoning. A key focus of ours is to create highly efficient algorithms that deliver impressive performance while minimizing resource use. We strive to reduce reliance on extensive human annotation, streamline training times, and lower inference costs. Ultimately, our goal is to build models that excel across a variety of tasks while being resource-conscious and accessible to all. Join us on this journey to reshape the future of NLP!</p>
        </section>

        <section class="news">
            <h2>News</h2>
            <ul>
                <li>
                    <strong>New Paper Released:</strong> "To Preserve or To Compress: An In-Depth Study of Connector Selection in Multimodal Large Language Models"
                    <br>
                    Authors: Junyan Lin, Haoran Chen, Dawei Zhu, Xiaoyu Shen
                    <br>
                    <a href="http://arxiv.org/abs/2410.06765" target="_blank">Paper</a> | 
                    <a href="https://github.com/EIT-NLP/Connector-Selection-for-MLLM" target="_blank">Code Repository</a>
                    <br>
                    This study explores the impact of connectors on the performance of Multimodal Large Language Models (MLLMs), providing important guidance for MLLM architecture design.
                </li>
                <li>
                    <strong>Research Highlight:</strong> "Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?"
                    <br>
                    Authors: Dawei Zhu, Pinzhen Chen, Miaoran Zhang, Barry Haddow, Xiaoyu Shen, Dietrich Klakow
                    <br>
                    <a href="https://arxiv.org/pdf/2404.14122" target="_blank">Paper</a> | 
                    <a href="https://github.com/uds-lsv/mt-sft" target="_blank">Code Repository</a>
                    <br>
                    This study revisits the importance of training data factors in fine-tuning LLMs for translation, revealing surprising findings about data volume and translation direction requirements.
                </li>
                <li>
                    <strong>Latest Publication:</strong> "The Accuracy Paradox in RLHF: When Better Reward Models Don't Yield Better Language Models"
                    <br>
                    Authors: Yanjun Chen, Dawei Zhu, Yirong Sun, Xinghao Chen, Wei Zhang, Xiaoyu Shen
                    <br>
                    <a href="https://arxiv.org/abs/2410.06554" target="_blank">Paper</a> | 
                    <a href="https://github.com/EIT-NLP/AccuracyParadox-RLHF" target="_blank">Code Repository</a>
                    <br>
                    This research reveals a surprising paradox in human feedback reinforcement learning, challenging the belief that stronger reward models always lead to better language model performance.
                </li>
            </ul>
            <a href="/publications" class="see-more">See more</a>
        </section>

        <section>
            <h2>Github</h2>
            <p>Our lab focus on open science and will release our code, model and dataset at <a href="https://github.com/eit-nlp" target="_blank" class="button-link">Visit our GitHub</a></p>
        </section>
    </main>

    <footer>
        <p>&copy; 2023 EIT NLP. All rights reserved.</p>
    </footer>

    <script src="script.js"></script>
</body>
</html>
